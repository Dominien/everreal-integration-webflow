/**
 * This file was auto-generated by Fern from our API Definition.
 */
import * as environments from "../../../../../../environments";
import * as core from "../../../../../../core";
import * as Webflow from "../../../../../index";
export declare namespace RobotsTxt {
    interface Options {
        environment?: core.Supplier<environments.WebflowEnvironment | string>;
        accessToken: core.Supplier<core.BearerToken>;
    }
    interface RequestOptions {
        /** The maximum time to wait for a response in seconds. */
        timeoutInSeconds?: number;
        /** The number of times to retry the request. Defaults to 2. */
        maxRetries?: number;
        /** A hook to abort the request. */
        abortSignal?: AbortSignal;
        /** Additional headers to include in the request. */
        headers?: Record<string, string>;
    }
}
export declare class RobotsTxt {
    protected readonly _options: RobotsTxt.Options;
    constructor(_options: RobotsTxt.Options);
    /**
     * Retrieve the robots.txt configuration for various user agents.
     *
     * Required scope: `site_config:read`
     *
     * @param {string} siteId - Unique identifier for a Site
     * @param {RobotsTxt.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link Webflow.BadRequestError}
     * @throws {@link Webflow.UnauthorizedError}
     * @throws {@link Webflow.NotFoundError}
     * @throws {@link Webflow.TooManyRequestsError}
     * @throws {@link Webflow.InternalServerError}
     *
     * @example
     *     await client.sites.robotsTxt.get("580e63e98c9a982ac9b8b741")
     */
    get(siteId: string, requestOptions?: RobotsTxt.RequestOptions): Promise<Webflow.Robots>;
    /**
     * Replace the `robots.txt` configuration for various user agents.
     *
     * Required scope | `site_config:write`
     *
     * @param {string} siteId - Unique identifier for a Site
     * @param {Webflow.Robots} request
     * @param {RobotsTxt.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link Webflow.BadRequestError}
     * @throws {@link Webflow.UnauthorizedError}
     * @throws {@link Webflow.NotFoundError}
     * @throws {@link Webflow.TooManyRequestsError}
     * @throws {@link Webflow.InternalServerError}
     *
     * @example
     *     await client.sites.robotsTxt.put("580e63e98c9a982ac9b8b741", {
     *         rules: [{
     *                 userAgent: "googlebot",
     *                 allows: ["/public"],
     *                 disallows: ["/vogon-poetry", "/total-perspective-vortex"]
     *             }],
     *         sitemap: "https://heartofgold.ship/sitemap.xml"
     *     })
     */
    put(siteId: string, request: Webflow.Robots, requestOptions?: RobotsTxt.RequestOptions): Promise<Webflow.Robots>;
    /**
     * Remove specific rules for a user-agent in your `robots.txt` file. To delete all rules for a user-agent, provide an empty rule set. This will remove the user-agent's entry entirely, leaving it subject to your site's default crawling behavior.
     *
     * **Note:** Deleting a user-agent with no rules will make the user-agent's access unrestricted unless other directives apply.
     *
     * Required scope: `site_config:write`
     *
     * @param {string} siteId - Unique identifier for a Site
     * @param {Webflow.Robots} request
     * @param {RobotsTxt.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link Webflow.BadRequestError}
     * @throws {@link Webflow.UnauthorizedError}
     * @throws {@link Webflow.NotFoundError}
     * @throws {@link Webflow.TooManyRequestsError}
     * @throws {@link Webflow.InternalServerError}
     *
     * @example
     *     await client.sites.robotsTxt.delete("580e63e98c9a982ac9b8b741", {
     *         rules: [{
     *                 userAgent: "*",
     *                 allows: ["/public"],
     *                 disallows: ["/bubbles"]
     *             }]
     *     })
     */
    delete(siteId: string, request: Webflow.Robots, requestOptions?: RobotsTxt.RequestOptions): Promise<Webflow.Robots>;
    /**
     * Update the `robots.txt` configuration for various user agents.
     *
     * Required scope | `site_config:write`
     *
     * @param {string} siteId - Unique identifier for a Site
     * @param {Webflow.Robots} request
     * @param {RobotsTxt.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link Webflow.BadRequestError}
     * @throws {@link Webflow.UnauthorizedError}
     * @throws {@link Webflow.NotFoundError}
     * @throws {@link Webflow.TooManyRequestsError}
     * @throws {@link Webflow.InternalServerError}
     *
     * @example
     *     await client.sites.robotsTxt.patch("580e63e98c9a982ac9b8b741", {
     *         rules: [{
     *                 userAgent: "googlebot",
     *                 allows: ["/public"],
     *                 disallows: ["/vogon-poetry", "/total-perspective-vortex"]
     *             }],
     *         sitemap: "https://heartofgold.ship/sitemap.xml"
     *     })
     */
    patch(siteId: string, request: Webflow.Robots, requestOptions?: RobotsTxt.RequestOptions): Promise<Webflow.Robots>;
    protected _getAuthorizationHeader(): Promise<string>;
}
